{
  "generated_at_utc": "2026-02-20T02:37:45.055657Z",
  "search_query": "(\"large language model\" OR LLM OR RAG) AND (biostatistics OR medical OR clinical)",
  "count": 15,
  "papers": [
    {
      "title": "Multi-Round Human-AI Collaboration with User-Specified Requirements",
      "authors": [
        "Sima Noorani",
        "Shayan Kiyani",
        "Hamed Hassani",
        "George Pappas"
      ],
      "abstract": "As humans increasingly rely on multiround conversational AI for high stakes decisions, principled frameworks are needed to ensure such interactions reliably improve decision quality. We adopt a human centric view governed by two principles: counterfactual harm, ensuring the AI does not undermine human strengths, and complementarity, ensuring it adds value where the human is prone to err. We formalize these concepts via user defined rules, allowing users to specify exactly what harm and complementarity mean for their specific task. We then introduce an online, distribution free algorithm with finite sample guarantees that enforces the user-specified constraints over the collaboration dynamics. We evaluate our framework across two interactive settings: LLM simulated collaboration on a medical diagnostic task and a human crowdsourcing study on a pictorial reasoning task. We show that our online procedure maintains prescribed counterfactual harm and complementarity violation rates even under nonstationary interaction dynamics. Moreover, tightening or loosening these constraints produces predictable shifts in downstream human accuracy, confirming that the two principles serve as practical levers for steering multi-round collaboration toward better decision quality without the need to model or constrain human behavior.",
      "pdf_url": "https://arxiv.org/pdf/2602.17646v1",
      "arxiv_url": "https://arxiv.org/abs/2602.17646v1",
      "published": "2026-02-19T18:54:34Z",
      "updated": "2026-02-19T18:54:34Z",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to Obstetrics",
      "authors": [
        "Baris Karacan",
        "Barbara Di Eugenio",
        "Patrick Thornton"
      ],
      "abstract": "Clinical free-text notes contain vital patient information. They are structured into labelled sections; recognizing these sections has been shown to support clinical decision-making and downstream NLP tasks. In this paper, we advance clinical section segmentation through three key contributions. First, we curate a new de-identified, section-labeled obstetrics notes dataset, to supplement the medical domains covered in public corpora such as MIMIC-III, on which most existing segmentation approaches are trained. Second, we systematically evaluate transformer-based supervised models for section segmentation on a curated subset of MIMIC-III (in-domain), and on the new obstetrics dataset (out-of-domain). Third, we conduct the first head-to-head comparison of supervised models for medical section segmentation with zero-shot large language models. Our results show that while supervised models perform strongly in-domain, their performance drops substantially out-of-domain. In contrast, zero-shot models demonstrate robust out-of-domain adaptability once hallucinated section headers are corrected. These findings underscore the importance of developing domain-specific clinical resources and highlight zero-shot segmentation as a promising direction for applying healthcare NLP beyond well-studied corpora, as long as hallucinations are appropriately managed.",
      "pdf_url": "https://arxiv.org/pdf/2602.17513v1",
      "arxiv_url": "https://arxiv.org/abs/2602.17513v1",
      "published": "2026-02-19T16:25:07Z",
      "updated": "2026-02-19T16:25:07Z",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian",
      "authors": [
        "Pietro Ferrazzi",
        "Mattia Franzin",
        "Alberto Lavelli",
        "Bernardo Magnini"
      ],
      "abstract": "Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether \"small\" LLMs (around one billion parameters) can effectively perform medical tasks while maintaining competitive accuracy. We evaluate models from three major families-Llama-3, Gemma-3, and Qwen3-across 20 clinical NLP tasks among Named Entity Recognition, Relation Extraction, Case Report Form Filling, Question Answering, and Argument Mining. We systematically compare a range of adaptation strategies, both at inference time (few-shot prompting, constraint decoding) and at training time (supervised fine-tuning, continual pretraining). Fine-tuning emerges as the most effective approach, while the combination of few-shot prompting and constraint decoding offers strong lower-resource alternatives. Our results show that small LLMs can match or even surpass larger baselines, with our best configuration based on Qwen3-1.7B achieving an average score +9.2 points higher than Qwen3-32B. We release a comprehensive collection of all the publicly available Italian medical datasets for NLP tasks, together with our top-performing models. Furthermore, we release an Italian dataset of 126M words from the Emergency Department of an Italian Hospital, and 175M words from various sources that we used for continual pre-training.",
      "pdf_url": "https://arxiv.org/pdf/2602.17475v1",
      "arxiv_url": "https://arxiv.org/abs/2602.17475v1",
      "published": "2026-02-19T15:38:46Z",
      "updated": "2026-02-19T15:38:46Z",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions",
      "authors": [
        "Hui Min Wong",
        "Philip Heesen",
        "Pascal Janetzky",
        "Martin Bendszus",
        "Stefan Feuerriegel"
      ],
      "abstract": "Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinicians reason over multiple potential conditions through iterative questioning to resolve uncertainty. This process requires considering differential diagnoses and actively excluding emergencies that demand immediate intervention. Yet, the ability of medical LLMs to generate informative follow-up questions and thus reason over differential diagnoses remains underexplored. Here, we introduce MedClarify, an AI agent for information-seeking that can generate follow-up questions for iterative reasoning to support diagnostic decision-making. Specifically, MedClarify computes a list of candidate diagnoses analogous to a differential diagnosis, and then proactively generates follow-up questions aimed at reducing diagnostic uncertainty. By selecting the question with the highest expected information gain, MedClarify enables targeted, uncertainty-aware reasoning to improve diagnostic performance. In our experiments, we first demonstrate the limitations of current LLMs in medical reasoning, which often yield multiple, similarly likely diagnoses, especially when patient cases are incomplete or relevant information for diagnosis is missing. We then show that our information-theoretic reasoning approach can generate effective follow-up questioning and thereby reduces diagnostic errors by ~27 percentage points (p.p.) compared to a standard single-shot LLM baseline. Altogether, MedClarify offers a path to improve medical LLMs through agentic information-seeking and to thus promote effective dialogues with medical LLMs that reflect the iterative and uncertain nature of real-world clinical reasoning.",
      "pdf_url": "https://arxiv.org/pdf/2602.17308v1",
      "arxiv_url": "https://arxiv.org/abs/2602.17308v1",
      "published": "2026-02-19T12:19:12Z",
      "updated": "2026-02-19T12:19:12Z",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Lyapunov Spectral Analysis of Speech Embedding Trajectories in Psychosis",
      "authors": [
        "Jelena Vasic",
        "Branislav Andjelic",
        "Ana Mancic",
        "Dusica Filipovic Djurdjevic",
        "Ljiljana Mihic",
        "Aleksandar Kovacevic",
        "Nadja P. Maric",
        "Aleksandra Maluckov"
      ],
      "abstract": "We analyze speech embeddings from structured clinical interviews of psychotic patients and healthy controls by treating language production as a high-dimensional dynamical process. Lyapunov exponent (LE) spectra are computed from word-level and answer-level embeddings generated by two distinct large language models, allowing us to assess the stability of the conclusions with respect to different embedding presentations. Word-level embeddings exhibit uniformly contracting dynamics with no positive LE, while answer-level embeddings, in spite of the overall contraction, display a number of positive LEs and higher-dimensional attractors. The resulting LE spectra robustly separate psychotic from healthy speech, while differentiation within the psychotic group is not statistically significant overall, despite a tendency of the most severe cases to occupy distinct dynamical regimes. These findings indicate that nonlinear dynamical invariants of speech embeddings provide a physics-inspired probe of disordered cognition whose conclusions remain stable across embedding models.",
      "pdf_url": "https://arxiv.org/pdf/2602.16273v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16273v1",
      "published": "2026-02-18T08:46:46Z",
      "updated": "2026-02-18T08:46:46Z",
      "categories": [
        "nlin.AO",
        "cs.CL"
      ]
    },
    {
      "title": "LiveClin: A Live Clinical Benchmark without Leakage",
      "authors": [
        "Xidong Wang",
        "Shuqi Guo",
        "Yue Shen",
        "Junying Chen",
        "Jian Wang",
        "Jinjie Gu",
        "Ping Zhang",
        "Lei Liu",
        "Benyou Wang"
      ],
      "abstract": "The reliability of medical LLM evaluation is critically undermined by data contamination and knowledge obsolescence, leading to inflated scores on static benchmarks. To address these challenges, we introduce LiveClin, a live benchmark designed for approximating real-world clinical practice. Built from contemporary, peer-reviewed case reports and updated biannually, LiveClin ensures clinical currency and resists data contamination. Using a verified AI-human workflow involving 239 physicians, we transform authentic patient cases into complex, multimodal evaluation scenarios that span the entire clinical pathway. The benchmark currently comprises 1,407 case reports and 6,605 questions. Our evaluation of 26 models on LiveClin reveals the profound difficulty of these real-world scenarios, with the top-performing model achieving a Case Accuracy of just 35.7%. In benchmarking against human experts, Chief Physicians achieved the highest accuracy, followed closely by Attending Physicians, with both surpassing most models. LiveClin thus provides a continuously evolving, clinically grounded framework to guide the development of medical LLMs towards closing this gap and achieving greater reliability and real-world utility. Our data and code are publicly available at https://github.com/AQ-MedAI/LiveClin.",
      "pdf_url": "https://arxiv.org/pdf/2602.16747v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16747v1",
      "published": "2026-02-18T03:59:46Z",
      "updated": "2026-02-18T03:59:46Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Objective Alignment of Language Models for Personalized Psychotherapy",
      "authors": [
        "Mehrab Beikzadeh",
        "Yasaman Asadollah Salmanpour",
        "Ashima Suvarna",
        "Sriram Sankararaman",
        "Matteo Malgaroli",
        "Majid Sarrafzadeh",
        "Saadia Gabriel"
      ],
      "abstract": "Mental health disorders affect over 1 billion people worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI systems show therapeutic promise, current alignment approaches optimize objectives independently, failing to balance patient preferences with clinical safety. We survey 335 individuals with lived mental health experience to collect preference rankings across therapeutic dimensions, then develop a multi-objective alignment framework using direct preference optimization. We train reward models for six criteria -- empathy, safety, active listening, self-motivated change, trust/rapport, and patient autonomy -- and systematically compare multi-objective approaches against single-objective optimization, supervised fine-tuning, and parameter merging. Multi-objective DPO (MODPO) achieves superior balance (77.6% empathy, 62.6% safety) compared to single-objective optimization (93.6% empathy, 47.8% safety), and therapeutic criteria outperform general communication principles by 17.2%. Blinded clinician evaluation confirms MODPO is consistently preferred, with LLM-evaluator agreement comparable to inter-clinician reliability.",
      "pdf_url": "https://arxiv.org/pdf/2602.16053v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16053v1",
      "published": "2026-02-17T22:08:14Z",
      "updated": "2026-02-17T22:08:14Z",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "title": "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination",
      "authors": [
        "Amir Hosseinian",
        "MohammadReza Zare Shahneh",
        "Umer Mansoor",
        "Gilbert Szeto",
        "Kirill Karlin",
        "Nima Aghaeepour"
      ],
      "abstract": "Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.",
      "pdf_url": "https://arxiv.org/pdf/2602.16050v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16050v1",
      "published": "2026-02-17T21:58:17Z",
      "updated": "2026-02-17T21:58:17Z",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "BTReport: A Framework for Brain Tumor Radiology Report Generation with Clinically Relevant Features",
      "authors": [
        "Juampablo E. Heras Rivera",
        "Dickson T. Chen",
        "Tianyi Ren",
        "Daniel K. Low",
        "Asma Ben Abacha",
        "Alberto Santamaria-Pang",
        "Mehmet Kurt"
      ],
      "abstract": "Recent advances in radiology report generation (RRG) have been driven by large paired image-text datasets; however, progress in neuro-oncology has been limited due to a lack of open paired image-report datasets. Here, we introduce BTReport, an open-source framework for brain tumor RRG that constructs natural language radiology reports using deterministically extracted imaging features. Unlike existing approaches that rely on large general-purpose or fine-tuned vision-language models for both image interpretation and report composition, BTReport performs deterministic feature extraction for image analysis and uses large language models only for syntactic structuring and narrative formatting. By separating RRG into a deterministic feature extraction step and a report generation step, the generated reports are completely interpretable and less prone to hallucinations. We show that the features used for report generation are predictive of key clinical outcomes, including survival and IDH mutation status, and reports generated by BTReport are more closely aligned with reference clinical reports than existing baselines for RRG. Finally, we introduce BTReport-BraTS, a companion dataset that augments BraTS imaging with synthetically generated radiology reports produced with BTReport. Code for this project can be found at  https://github.com/KurtLabUW/BTReport.",
      "pdf_url": "https://arxiv.org/pdf/2602.16006v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16006v1",
      "published": "2026-02-17T20:55:00Z",
      "updated": "2026-02-17T20:55:00Z",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "CAMEL: An ECG Language Model for Forecasting Cardiac Events",
      "authors": [
        "Neelay Velingker",
        "Alaia Solko-Breslin",
        "Mayank Keoliya",
        "Seewon Choi",
        "Jiayi Xin",
        "Anika Marathe",
        "Alireza Oraii",
        "Rajat Deo",
        "Sameed Khatana",
        "Rajeev Alur",
        "Mayur Naik",
        "Eric Wong"
      ],
      "abstract": "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).",
      "pdf_url": "https://arxiv.org/pdf/2602.15677v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15677v1",
      "published": "2026-02-17T16:02:52Z",
      "updated": "2026-02-17T16:02:52Z",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ]
    },
    {
      "title": "LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models",
      "authors": [
        "Ahmed Khaled Khamis",
        "Hesham Ali"
      ],
      "abstract": "Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.",
      "pdf_url": "https://arxiv.org/pdf/2602.15675v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15675v1",
      "published": "2026-02-17T15:58:27Z",
      "updated": "2026-02-17T15:58:27Z",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation",
      "authors": [
        "Marco Salm\u00e8",
        "Federico Siciliano",
        "Fabrizio Silvestri",
        "Paolo Soda",
        "Rosa Sicilia",
        "Valerio Guarrasi"
      ],
      "abstract": "Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.",
      "pdf_url": "https://arxiv.org/pdf/2602.15650v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15650v1",
      "published": "2026-02-17T15:18:07Z",
      "updated": "2026-02-17T15:18:07Z",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit",
      "authors": [
        "Aswathy Velutharambath",
        "Amelie W\u00fchrl"
      ],
      "abstract": "Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect",
      "pdf_url": "https://arxiv.org/pdf/2602.15504v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15504v1",
      "published": "2026-02-17T11:21:40Z",
      "updated": "2026-02-17T11:21:40Z",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Improving LLM Reliability through Hybrid Abstention and Adaptive Detection",
      "authors": [
        "Ankit Sharma",
        "Nachiket Tapas",
        "Jyotiprakash Patra"
      ],
      "abstract": "Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.",
      "pdf_url": "https://arxiv.org/pdf/2602.15391v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15391v1",
      "published": "2026-02-17T07:00:09Z",
      "updated": "2026-02-17T07:00:09Z",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis",
      "authors": [
        "Pengfei Zhang",
        "Tianxin Xie",
        "Minghao Yang",
        "Li Liu"
      ],
      "abstract": "Deep learning-based respiratory auscultation is currently hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe class imbalance. To bridge these gaps, we present Resp-Agent, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A$^2$CA). Unlike static pipelines, Thinker-A$^2$CA serves as a central controller that actively identifies diagnostic weaknesses and schedules targeted synthesis in a closed loop. To address the representation gap, we introduce a Modality-Weaving Diagnoser that weaves EHR data with audio tokens via Strategic Global Attention and sparse audio anchors, capturing both long-range clinical context and millisecond-level transients. To address the data gap, we design a Flow Matching Generator that adapts a text-only Large Language Model (LLM) via modality injection, decoupling pathological content from acoustic style to synthesize hard-to-diagnose samples. As a foundation for these efforts, we introduce Resp-229k, a benchmark corpus of 229k recordings paired with LLM-distilled clinical narratives. Extensive experiments demonstrate that Resp-Agent consistently outperforms prior approaches across diverse evaluation settings, improving diagnostic robustness under data scarcity and long-tailed class imbalance. Our code and data are available at https://github.com/zpforlove/Resp-Agent.",
      "pdf_url": "https://arxiv.org/pdf/2602.15909v2",
      "arxiv_url": "https://arxiv.org/abs/2602.15909v2",
      "published": "2026-02-16T14:48:24Z",
      "updated": "2026-02-19T13:22:10Z",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.DB",
        "cs.HC",
        "cs.MA",
        "cs.SD"
      ]
    }
  ]
}