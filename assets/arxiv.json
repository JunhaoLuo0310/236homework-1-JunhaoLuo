{
  "generated_at_utc": "2026-02-19T02:43:24.513829Z",
  "search_query": "(\"large language model\" OR LLM OR RAG) AND (biostatistics OR medical OR clinical)",
  "count": 15,
  "papers": [
    {
      "title": "Lyapunov Spectral Analysis of Speech Embedding Trajectories in Psychosis",
      "authors": [
        "Jelena Vasic",
        "Branislav Andjelic",
        "Ana Mancic",
        "Dusica Filipovic Djurdjevic",
        "Ljiljana Mihic",
        "Aleksandar Kovacevic",
        "Nadja P. Maric",
        "Aleksandra Maluckov"
      ],
      "abstract": "We analyze speech embeddings from structured clinical interviews of psychotic patients and healthy controls by treating language production as a high-dimensional dynamical process. Lyapunov exponent (LE) spectra are computed from word-level and answer-level embeddings generated by two distinct large language models, allowing us to assess the stability of the conclusions with respect to different embedding presentations. Word-level embeddings exhibit uniformly contracting dynamics with no positive LE, while answer-level embeddings, in spite of the overall contraction, display a number of positive LEs and higher-dimensional attractors. The resulting LE spectra robustly separate psychotic from healthy speech, while differentiation within the psychotic group is not statistically significant overall, despite a tendency of the most severe cases to occupy distinct dynamical regimes. These findings indicate that nonlinear dynamical invariants of speech embeddings provide a physics-inspired probe of disordered cognition whose conclusions remain stable across embedding models.",
      "pdf_url": "https://arxiv.org/pdf/2602.16273v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16273v1",
      "published": "2026-02-18T08:46:46Z",
      "updated": "2026-02-18T08:46:46Z",
      "categories": [
        "nlin.AO",
        "cs.CL"
      ]
    },
    {
      "title": "Multi-Objective Alignment of Language Models for Personalized Psychotherapy",
      "authors": [
        "Mehrab Beikzadeh",
        "Yasaman Asadollah Salmanpour",
        "Ashima Suvarna",
        "Sriram Sankararaman",
        "Matteo Malgaroli",
        "Majid Sarrafzadeh",
        "Saadia Gabriel"
      ],
      "abstract": "Mental health disorders affect over 1 billion people worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI systems show therapeutic promise, current alignment approaches optimize objectives independently, failing to balance patient preferences with clinical safety. We survey 335 individuals with lived mental health experience to collect preference rankings across therapeutic dimensions, then develop a multi-objective alignment framework using direct preference optimization. We train reward models for six criteria -- empathy, safety, active listening, self-motivated change, trust/rapport, and patient autonomy -- and systematically compare multi-objective approaches against single-objective optimization, supervised fine-tuning, and parameter merging. Multi-objective DPO (MODPO) achieves superior balance (77.6% empathy, 62.6% safety) compared to single-objective optimization (93.6% empathy, 47.8% safety), and therapeutic criteria outperform general communication principles by 17.2%. Blinded clinician evaluation confirms MODPO is consistently preferred, with LLM-evaluator agreement comparable to inter-clinician reliability.",
      "pdf_url": "https://arxiv.org/pdf/2602.16053v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16053v1",
      "published": "2026-02-17T22:08:14Z",
      "updated": "2026-02-17T22:08:14Z",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination",
      "authors": [
        "Amir Hosseinian",
        "MohammadReza Zare Shahneh",
        "Umer Mansoor",
        "Gilbert Szeto",
        "Kirill Karlin",
        "Nima Aghaeepour"
      ],
      "abstract": "Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.",
      "pdf_url": "https://arxiv.org/pdf/2602.16050v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16050v1",
      "published": "2026-02-17T21:58:17Z",
      "updated": "2026-02-17T21:58:17Z",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "BTReport: A Framework for Brain Tumor Radiology Report Generation with Clinically Relevant Features",
      "authors": [
        "Juampablo E. Heras Rivera",
        "Dickson T. Chen",
        "Tianyi Ren",
        "Daniel K. Low",
        "Asma Ben Abacha",
        "Alberto Santamaria-Pang",
        "Mehmet Kurt"
      ],
      "abstract": "Recent advances in radiology report generation (RRG) have been driven by large paired image-text datasets; however, progress in neuro-oncology has been limited due to a lack of open paired image-report datasets. Here, we introduce BTReport, an open-source framework for brain tumor RRG that constructs natural language radiology reports using deterministically extracted imaging features. Unlike existing approaches that rely on large general-purpose or fine-tuned vision-language models for both image interpretation and report composition, BTReport performs deterministic feature extraction for image analysis and uses large language models only for syntactic structuring and narrative formatting. By separating RRG into a deterministic feature extraction step and a report generation step, the generated reports are completely interpretable and less prone to hallucinations. We show that the features used for report generation are predictive of key clinical outcomes, including survival and IDH mutation status, and reports generated by BTReport are more closely aligned with reference clinical reports than existing baselines for RRG. Finally, we introduce BTReport-BraTS, a companion dataset that augments BraTS imaging with synthetically generated radiology reports produced with BTReport. Code for this project can be found at  https://github.com/KurtLabUW/BTReport.",
      "pdf_url": "https://arxiv.org/pdf/2602.16006v1",
      "arxiv_url": "https://arxiv.org/abs/2602.16006v1",
      "published": "2026-02-17T20:55:00Z",
      "updated": "2026-02-17T20:55:00Z",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "CAMEL: An ECG Language Model for Forecasting Cardiac Events",
      "authors": [
        "Neelay Velingker",
        "Alaia Solko-Breslin",
        "Mayank Keoliya",
        "Seewon Choi",
        "Jiayi Xin",
        "Anika Marathe",
        "Alireza Oraii",
        "Rajat Deo",
        "Sameed Khatana",
        "Rajeev Alur",
        "Mayur Naik",
        "Eric Wong"
      ],
      "abstract": "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).",
      "pdf_url": "https://arxiv.org/pdf/2602.15677v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15677v1",
      "published": "2026-02-17T16:02:52Z",
      "updated": "2026-02-17T16:02:52Z",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ]
    },
    {
      "title": "LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models",
      "authors": [
        "Ahmed Khaled Khamis",
        "Hesham Ali"
      ],
      "abstract": "Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.",
      "pdf_url": "https://arxiv.org/pdf/2602.15675v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15675v1",
      "published": "2026-02-17T15:58:27Z",
      "updated": "2026-02-17T15:58:27Z",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation",
      "authors": [
        "Marco Salm\u00e8",
        "Federico Siciliano",
        "Fabrizio Silvestri",
        "Paolo Soda",
        "Rosa Sicilia",
        "Valerio Guarrasi"
      ],
      "abstract": "Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.",
      "pdf_url": "https://arxiv.org/pdf/2602.15650v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15650v1",
      "published": "2026-02-17T15:18:07Z",
      "updated": "2026-02-17T15:18:07Z",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit",
      "authors": [
        "Aswathy Velutharambath",
        "Amelie W\u00fchrl"
      ],
      "abstract": "Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect",
      "pdf_url": "https://arxiv.org/pdf/2602.15504v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15504v1",
      "published": "2026-02-17T11:21:40Z",
      "updated": "2026-02-17T11:21:40Z",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Improving LLM Reliability through Hybrid Abstention and Adaptive Detection",
      "authors": [
        "Ankit Sharma",
        "Nachiket Tapas",
        "Jyotiprakash Patra"
      ],
      "abstract": "Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.",
      "pdf_url": "https://arxiv.org/pdf/2602.15391v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15391v1",
      "published": "2026-02-17T07:00:09Z",
      "updated": "2026-02-17T07:00:09Z",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis",
      "authors": [
        "Pengfei Zhang",
        "Tianxin Xie",
        "Minghao Yang",
        "Li Liu"
      ],
      "abstract": "Deep learning-based respiratory auscultation is currently hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe class imbalance. To bridge these gaps, we present Resp-Agent, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A$^2$CA). Unlike static pipelines, Thinker-A$^2$CA serves as a central controller that actively identifies diagnostic weaknesses and schedules targeted synthesis in a closed loop. To address the representation gap, we introduce a Modality-Weaving Diagnoser that weaves EHR data with audio tokens via Strategic Global Attention and sparse audio anchors, capturing both long-range clinical context and millisecond-level transients. To address the data gap, we design a Flow Matching Generator that adapts a text-only Large Language Model (LLM) via modality injection, decoupling pathological content from acoustic style to synthesize hard-to-diagnose samples. As a foundation for these efforts, we introduce Resp-229k, a benchmark corpus of 229k recordings paired with LLM-distilled clinical narratives. Extensive experiments demonstrate that Resp-Agent consistently outperforms prior approaches across diverse evaluation settings, improving diagnostic robustness under data scarcity and long-tailed class imbalance. Our code and data are available at https://github.com/zpforlove/Resp-Agent.",
      "pdf_url": "https://arxiv.org/pdf/2602.15909v1",
      "arxiv_url": "https://arxiv.org/abs/2602.15909v1",
      "published": "2026-02-16T14:48:24Z",
      "updated": "2026-02-16T14:48:24Z",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.DB",
        "cs.HC",
        "cs.MA",
        "cs.SD"
      ]
    },
    {
      "title": "Arbor: A Framework for Reliable Navigation of Critical Conversation Flows",
      "authors": [
        "Lu\u00eds Silva",
        "Diogo Gon\u00e7alves",
        "Catarina Farinha",
        "Clara Matos",
        "Lu\u00eds Ungaro"
      ],
      "abstract": "Large language models struggle to maintain strict adherence to structured workflows in high-stakes domains such as healthcare triage. Monolithic approaches that encode entire decision structures within a single prompt are prone to instruction-following degradation as prompt length increases, including lost-in-the-middle effects and context window overflow. To address this gap, we present Arbor, a framework that decomposes decision tree navigation into specialized, node-level tasks. Decision trees are standardized into an edge-list representation and stored for dynamic retrieval. At runtime, a directed acyclic graph (DAG)-based orchestration mechanism iteratively retrieves only the outgoing edges of the current node, evaluates valid transitions via a dedicated LLM call, and delegates response generation to a separate inference step. The framework is agnostic to the underlying decision logic and model provider. Evaluated against single-prompt baselines across 10 foundation models using annotated turns from real clinical triage conversations. Arbor improves mean turn accuracy by 29.4 percentage points, reduces per-turn latency by 57.1%, and achieves an average 14.4x reduction in per-turn cost. These results indicate that architectural decomposition reduces dependence on intrinsic model capability, enabling smaller models to match or exceed larger models operating under single-prompt baselines.",
      "pdf_url": "https://arxiv.org/pdf/2602.14643v2",
      "arxiv_url": "https://arxiv.org/abs/2602.14643v2",
      "published": "2026-02-16T11:09:02Z",
      "updated": "2026-02-17T16:44:27Z",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Assessing Large Language Models for Medical QA: Zero-Shot and LLM-as-a-Judge Evaluation",
      "authors": [
        "Shefayat E Shams Adib",
        "Ahmed Alfey Sani",
        "Ekramul Alam Esham",
        "Ajwad Abrar",
        "Tareque Mohmud Chowdhury"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have gained significant traction in medical domain, especially in developing a QA systems to Medical QA systems for enhancing access to healthcare in low-resourced settings. This paper compares five LLMs deployed between April 2024 and August 2025 for medical QA, using the iCliniq dataset, containing 38,000 medical questions and answers of diverse specialties. Our models include Llama-3-8B-Instruct, Llama 3.2 3B, Llama 3.3 70B Instruct, Llama-4-Maverick-17B-128E-Instruct, and GPT-5-mini. We are using a zero-shot evaluation methodology and using BLEU and ROUGE metrics to evaluate performance without specialized fine-tuning. Our results show that larger models like Llama 3.3 70B Instruct outperform smaller models, consistent with observed scaling benefits in clinical tasks. It is notable that, Llama-4-Maverick-17B exhibited more competitive results, thus highlighting evasion efficiency trade-offs relevant for practical deployment. These findings align with advancements in LLM capabilities toward professional-level medical reasoning and reflect the increasing feasibility of LLM-supported QA systems in the real clinical environments. This benchmark aims to serve as a standardized setting for future study to minimize model size, computational resources and to maximize clinical utility in medical NLP applications.",
      "pdf_url": "https://arxiv.org/pdf/2602.14564v1",
      "arxiv_url": "https://arxiv.org/abs/2602.14564v1",
      "published": "2026-02-16T08:53:23Z",
      "updated": "2026-02-16T08:53:23Z",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Differentially Private Retrieval-Augmented Generation",
      "authors": [
        "Tingting Tang",
        "James Flemings",
        "Yongqin Wang",
        "Murali Annavaram"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is a widely used framework for reducing hallucinations in large language models (LLMs) on domain-specific tasks by retrieving relevant documents from a database to support accurate responses. However, when the database contains sensitive corpora, such as medical records or legal documents, RAG poses serious privacy risks by potentially exposing private information through its outputs. Prior work has demonstrated that one can practically craft adversarial prompts that force an LLM to regurgitate the augmented contexts. A promising direction is to integrate differential privacy (DP), a privacy notion that offers strong formal guarantees, into RAG systems. However, naively applying DP mechanisms into existing systems often leads to significant utility degradation. Particularly for RAG systems, DP can reduce the usefulness of the augmented contexts leading to increase risk of hallucination from the LLMs. Motivated by these challenges, we present DP-KSA, a novel privacy-preserving RAG algorithm that integrates DP using the propose-test-release paradigm. DP-KSA follows from a key observation that most question-answering (QA) queries can be sufficiently answered with a few keywords. Hence, DP-KSA first obtains an ensemble of relevant contexts, each of which will be used to generate a response from an LLM. We utilize these responses to obtain the most frequent keywords in a differentially private manner. Lastly, the keywords are augmented into the prompt for the final output. This approach effectively compresses the semantic space while preserving both utility and privacy. We formally show that DP-KSA provides formal DP guarantees on the generated output with respect to the RAG database. We evaluate DP-KSA on two QA benchmarks using three instruction-tuned LLMs, and our empirical results demonstrate that DP-KSA achieves a strong privacy-utility tradeoff.",
      "pdf_url": "https://arxiv.org/pdf/2602.14374v1",
      "arxiv_url": "https://arxiv.org/abs/2602.14374v1",
      "published": "2026-02-16T00:52:57Z",
      "updated": "2026-02-16T00:52:57Z",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "DeepFusion: Accelerating MoE Training via Federated Knowledge Distillation from Heterogeneous Edge Devices",
      "authors": [
        "Songyuan Li",
        "Jia Hu",
        "Ahmed M. Abdelmoniem",
        "Geyong Min",
        "Haojun Huang",
        "Jiwei Huang"
      ],
      "abstract": "Recent Mixture-of-Experts (MoE)-based large language models (LLMs) such as Qwen-MoE and DeepSeek-MoE are transforming generative AI in natural language processing. However, these models require vast and diverse training data. Federated learning (FL) addresses this challenge by leveraging private data from heterogeneous edge devices for privacy-preserving MoE training. Nonetheless, traditional FL approaches require devices to host local MoE models, which is impractical for resource-constrained devices due to large model sizes. To address this, we propose DeepFusion, the first scalable federated MoE training framework that enables the fusion of heterogeneous on-device LLM knowledge via federated knowledge distillation, yielding a knowledge-abundant global MoE model. Specifically, DeepFusion features each device to independently configure and train an on-device LLM tailored to its own needs and hardware limitations. Furthermore, we propose a novel View-Aligned Attention (VAA) module that integrates multi-stage feature representations from the global MoE model to construct a predictive perspective aligned with on-device LLMs, thereby enabling effective cross-architecture knowledge distillation. By explicitly aligning predictive perspectives, VAA resolves the view-mismatch problem in traditional federated knowledge distillation, which arises from heterogeneity in model architectures and prediction behaviors between on-device LLMs and the global MoE model. Experiments with industry-level MoE models (Qwen-MoE and DeepSeek-MoE) and real-world datasets (medical and finance) demonstrate that DeepFusion achieves performance close to centralized MoE training. Compared with key federated MoE baselines, DeepFusion reduces communication costs by up to 71% and improves token perplexity by up to 5.28%.",
      "pdf_url": "https://arxiv.org/pdf/2602.14301v1",
      "arxiv_url": "https://arxiv.org/abs/2602.14301v1",
      "published": "2026-02-15T20:25:50Z",
      "updated": "2026-02-15T20:25:50Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Explainable Interictal Epileptiform Discharge Detection Method Based on Scalp EEG and Retrieval-Augmented Generation",
      "authors": [
        "Yu Zhu",
        "Jiayang Guo",
        "Jun Jiang",
        "Peipei Gu",
        "Xin Shu",
        "Duo Chen"
      ],
      "abstract": "The detection of interictal epileptiform discharge (IED) is crucial for the diagnosis of epilepsy, but automated methods often lack interpretability. This study proposes IED-RAG, an explainable multimodal framework for joint IED detection and report generation. Our approach employs a dual-encoder to extract electrophysiological and semantic features, aligned via contrastive learning in a shared EEG-text embedding space. During inference, clinically relevant EEG-text pairs are retrieved from a vector database as explicit evidence to condition a large language model (LLM) for the generation of evidence-based reports. Evaluated on a private dataset from Wuhan Children's Hospital and the public TUH EEG Events Corpus (TUEV), the framework achieved balanced accuracies of 89.17\\% and 71.38\\%, with BLEU scores of 89.61\\% and 64.14\\%, respectively. The results demonstrate that retrieval of explicit evidence enhances both diagnostic performance and clinical interpretability compared to standard black-box methods.",
      "pdf_url": "https://arxiv.org/pdf/2602.14170v1",
      "arxiv_url": "https://arxiv.org/abs/2602.14170v1",
      "published": "2026-02-15T14:51:26Z",
      "updated": "2026-02-15T14:51:26Z",
      "categories": [
        "eess.SP"
      ]
    }
  ]
}